{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RedEnrique.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14jE5ECmG6sN6KUzqW5sU4QXi_q381NrX",
      "authorship_tag": "ABX9TyNK7VgsmH2lqzPHdidX/I9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enrjorarr/ProyectoIA/blob/master/RedEnrique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuK-dnd_QUbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
        "from tensorflow.python.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F2Cz6QoR6BP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d971338e-3d32-40a9-8dbd-35a44c0b31b3"
      },
      "source": [
        "#ConexiÃ³n con google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Rutas de paquetes de datos.\n",
        " \n",
        "train_path = '/content/drive/My Drive/ProyectoIA/Datos/train'\n",
        "test_path = '/content/drive/My Drive/ProyectoIA/Datos/test'\n",
        "val_path = '/content/drive/My Drive/ProyectoIA/Datos/val'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rjX30mxRmzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Datos\n",
        "\n",
        "epocas = 6\n",
        "altura, longitud = 100, 100\n",
        "batch_size = 32\n",
        "pasos = 1000\n",
        "pasos_validacion = 200\n",
        "filtrosConv1 = 32\n",
        "filtrosConv2 = 64\n",
        "tamano_filtro1 = (3,3)\n",
        "tamano_filtro2 = (2,2)\n",
        "tamano_pool = (2,2)\n",
        "clases = 9\n",
        "lr = 0.005"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVDh3HjvXsem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entrenamiento_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.3,\n",
        "    zoom_range = 0.3,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "validacion_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkMZ4yHkYzo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb52e54c-180f-4f5b-9e10-4c40819df434"
      },
      "source": [
        "imagen_entrenamiento = entrenamiento_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size = (altura, longitud),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12002 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VeK38pPZGvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b25b7ef4-8658-468a-c773-9f0697864a25"
      },
      "source": [
        "imagen_validacion = validacion_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size = (altura, longitud),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3005 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVmRQZmHdlle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "8ecf90b5-9e81-4023-c32f-7351d18e17da"
      },
      "source": [
        "Adam = tf.keras.optimizers.Adam(\n",
        "    learning_rate=lr,\n",
        "    name='Adam'\n",
        ")\n",
        "\n",
        "cnn = Sequential()\n",
        "\n",
        "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding='same', input_shape = (altura, longitud, 3), activation='relu'))\n",
        "\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "#cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding='same', activation='relu'))\n",
        "\n",
        "#cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "cnn.add(Flatten())\n",
        "\n",
        "cnn.add(Dense(64, activation='relu'))\n",
        "\n",
        "cnn.add(Dropout(0.5))\n",
        "\n",
        "cnn.add(Dense(64, activation='relu'))\n",
        "\n",
        "cnn.add(Dropout(0.5))\n",
        "\n",
        "cnn.add(Dense(clases, activation='softmax'))\n",
        "\n",
        "cnn.compile(loss = 'categorical_crossentropy', optimizer=Adam, metrics=['accuracy'])\n",
        "\n",
        "cnn.summary()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 100, 100, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 50, 50, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 80000)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                5120064   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 9)                 585       \n",
            "=================================================================\n",
            "Total params: 5,125,705\n",
            "Trainable params: 5,125,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhQC3KQMhBPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4421ed13-3944-43c4-f66d-9e7dd42873ee"
      },
      "source": [
        "cnn.fit(imagen_entrenamiento, steps_per_epoch=pasos, epochs=epocas, validation_data=imagen_validacion, validation_steps=pasos_validacion)\n",
        "\n",
        "cnn.save('/content/drive/My Drive/ProyectoIA/Modelos/modelo.h5')\n",
        "cnn.save_weights('/content/drive/My Drive/ProyectoIA/Modelos/pesos.h5')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            " 376/1000 [==========>...................] - ETA: 2:11:12 - loss: 1.8853 - accuracy: 0.5119WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n",
            " 376/1000 [==========>...................] - 6235s 17s/step - loss: 1.8853 - accuracy: 0.5119 - val_loss: 1.5371 - val_accuracy: 0.5245\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}